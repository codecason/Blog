---
title: 变分法求函数极值
date: 2025-11-04 10:00:00
tags: 数学，贝叶斯，VAE
layout: post
mathjax: true
---

### 一、变分法的来历
变分法的诞生并非偶然，而是17-18世纪数学家为解决非数值极值问题发起的一次数学革命，其发展历程可分为问题驱动--理论奠基--体系完善三个阶段。

#### 1. 起源：两个无法用常规微积分解决的经典难题
在变分法出现前，微积分已能解决求某个变量的函数极值（如求 $ y=x^2 $ 的最小值），但面对求函数的函数（泛函）极值时完全失效，这一矛盾因两个经典问题被彻底激化。

#### 1.1 **最速降线问题**

​	1696年，瑞士数学家约翰·伯努利在《教师学报》上提出挑战：在垂直平面内，给定A、B两点（A不在B正上方），若一个质点仅受重力作用从A滑到B，沿哪条曲线下滑时间最短？  

​	当时主流观点认为直线最短，但伯努利通过实验发现：质点沿曲线下滑的时间反而更短。他本人通过光的折射类比（将质点速度类比为光速，利用斯涅尔定律推导）得到答案——旋轮线，也就是称摆线，即一个圆在直线上滚动时，圆周上某点的运动轨迹，但该方法仅适用于这一特定问题，无法推广。

![image](../../../../images/function\fig1.png)

#### 1.2 等周问题

​	这一问题可追溯至古希腊：给定周长的封闭曲线，哪条围成的面积最大？ 古人凭几何直觉认为答案是圆，但始终无法用数学证明。17世纪，伽利略曾通过铁丝实验验证圆的面积最大，但缺乏理论支撑。直到1701年，雅各布·伯努利（约翰·伯努利的哥哥）尝试用无穷小分析解决，虽未成功，却为后续研究提供了思路——即通过比较相邻曲线的面积差异，找到最优曲线。

​	这两个问题的共性在于，待求目标不是某个数值，而是一条曲线（即一个函数），常规微积分的变量增量 $ \Delta x $无法描述曲线之间的差异，亟需一种全新的数学工具。

#### 2. 欧拉的泛函极值理论与《寻求具有某种极大或极小性质的曲线的方法》
​	1728年，欧拉收到约翰·伯努利的学生法尼亚诺的求助，希望用通用方法解决最速降线问题。经过16年的研究，欧拉在1744年出版《寻求具有某种极大或极小性质的曲线的技巧》，标志着变分法正式成为一门独立学科。

​	欧拉的核心贡献在于提出了泛函概念，他将曲线的长度、面积、下滑时间等依赖于整个曲线的量，定义为泛函（记为 $ J[y] $），即输入是函数 $ y(x) $，输出是数值，明确了变分法的研究对象。同时，引入了变分符号 $ \delta $：类比微积分中的微分 $ dy $，用 $ \delta y $ 表示两个相邻曲线的差异（即 $ \delta y = \bar{y}(x) - y(x) $，其中 $ \bar{y}(x) $ 是围绕最优曲线 $ y(x) $ 的微小扰动），并推导出泛函极值的必要条件：若 $ J[y] $ 在 $ y(x) $ 处取极值，则泛函的变分 $ \delta J = 0 $。

​	最后也推导了首个变分方程：针对最简单的泛函形式 $ J[y] = \int_{a}^{b} F(x, y(x)) dx $，欧拉通过将泛函极值转化为积分极值，得到最优曲线需满足的方程 $ \frac{\partial F}{\partial y} = 0 $，为后续推广奠定基础。

#### 3. 拉格朗日的欧拉-拉格朗日方程
​	1755年，19岁的拉格朗日给欧拉写了一封信，提出一种更简洁的泛函极值推导方法——无需依赖几何直观，直接通过代数运算推导泛函极值条件。欧拉对此高度认可，并将这种方法命名为变分法（Calculus of Variations）。

​	于是就有了欧拉-拉格朗日方程，这是变分法的核心公式，

​	对于一般形式的泛函 $ J[y] = \int_{a}^{b} F(x, y(x), y'(x)) dx $（其中 $ y'(x) = \frac{dy}{dx} $ 是 $ y(x) $ 的导数），若 $ y(x) $ 是使 $ J[y] $ 取极值的曲线，且满足边界条件 $ y(a) = y_a $、$ y(b) = y_b $，则 $ y(x) $ 必须满足：  
$$ \frac{\partial F}{\partial y} - \frac{d}{dx} \left( \frac{\partial F}{\partial y'} \right) = 0$$  

​	这一方程将泛函极值问题转化为常微分方程求解问题，也就是说只要解出欧拉-拉格朗日方程，就能得到最优曲线。例如，用该方程解决最速降线问题时，可设泛函 $ J[y] = \int_{x_1}^{x_2} \frac{\sqrt{1 + (y')^2}}{\sqrt{2gy}} dx $（其中 $ g $ 是重力加速度），代入欧拉-拉格朗日方程后，可解出 $ x = \frac{c}{2}(\theta - \sin\theta) $、$ y = \frac{c}{2}(1 - \cos\theta) $，即旋轮线的参数方程，完美验证了伯努利的结论。

​	19世纪后，柯西、魏尔斯特拉斯等数学家进一步完善了变分法的极值充分条件（如魏尔斯特拉斯的 $ E $-函数判别法），并将其推广到多变量函数、复变函数等领域，形成了完整的数学体系。

​	变分法的本质是寻找最优函数，这一核心能力使其成为连接数学、物理、工程等领域的桥梁，从解释自然规律到解决实际问题，应用范围贯穿基础科学与前沿技术。

变分法是经典物理的第一性原理工具，许多核心定律都可通过泛函极值推导得出，最典型的是**哈密顿原理**（Hamilton's Principle）——物理系统的真实运动轨迹，必然使‘作用量’（Action）泛函取极值。


### 二、变分法的核心原理
要理解变分法，需从核心概念极值条件方程推导三个层面逐步深入，掌握如何将泛函极值转化为微分方程的关键逻辑。

#### 1. 核心概念：泛函、变分与泛函导数
变分法的所有推导都基于三个核心概念，需先明确其定义与物理意义：

- **泛函（Functional）**：依赖于函数的数值映射  
  设 $ y(x) $ 是定义在区间 $ [a,b] $ 上的函数（满足一定光滑性，如连续可导），若对每个这样的 $ y(x) $，都有一个确定的数值 $ J $ 与之对应，则称 $ J $ 是 $ y(x) $ 的泛函，记为 $ J = J[y(x)] $ 或简记为 $ J[y] $。  
  常见泛函例子：
  - 曲线长度：$ L[y] = \int_{a}^{b} \sqrt{1 + (y')^2} dx $（输入曲线 $ y(x) $，输出长度）；
  - 函数的积分：$ J[y] = \int_{a}^{b} y(x) dx $（输入函数 $ y(x) $，输出积分值）；
  - 物理作用量：$ S[y] = \int_{t_1}^{t_2} (T - V) dt $（输入运动轨迹 $ y(t) $，输出作用量）。

- **变分（Variation）**：函数的微小扰动  
  类比微积分中变量的增量 $ \Delta x $，变分是函数的微小扰动。设 $ y(x) $ 是某一函数，$ \eta(x) $ 是定义在 $ [a,b] $ 上的扰动函数（满足边界条件 $ \eta(a) = \eta(b) = 0 $，即边界处无扰动），$ \varepsilon $ 是微小参数（$ |\varepsilon| \ll 1 $），则函数 $ y(x) $ 的变分 $ \delta y $ 定义为： 
  $$ \delta y = \varepsilon \eta(x)$$ 
  对应的扰动函数为 $ y_\varepsilon(x) = y(x) + \delta y = y(x) + \varepsilon \eta(x) $，其导数的变分为 $ \delta y' = \frac{d}{dx}(\delta y) = \varepsilon \eta'(x) $（变分与导数可交换顺序）。

- **泛函的变分（Variation of Functional）**：泛函增量的线性主部  
  当函数从 $ y(x) $ 扰动到 $ y_\varepsilon(x) $ 时，泛函的增量为 $ \Delta J = J[y_\varepsilon] - J[y] $。将 $ \Delta J $ 按 $ \varepsilon $ 展开为泰勒级数：  
  $$ \Delta J = \delta J + \frac{1}{2!} \delta^2 J + \cdots$$  
  其中，$ \delta J $ 是 $ \varepsilon $ 的一次项（线性主部），称为泛函的一阶变分；$ \delta^2 J $ 是 $ \varepsilon $ 的二次项，称为泛函的二阶变分。变分法中，泛函取极值的必要条件是**一阶变分等于零**（$ \delta J = 0 $），类比微积分中函数极值的必要条件是一阶导数等于零。

#### 2. 泛函极值的必要条件：一阶变分等于零（$ \delta J = 0 $）
以单变量函数的泛函 $ J[y] = \int_{a}^{b} F(x, y, y') dx $ 为例，推导泛函取极值的必要条件。

步骤1：构造扰动泛函  
设扰动函数为 $ y_\varepsilon(x) = y(x) + \varepsilon \eta(x) $，代入泛函得：  
$$ J(\varepsilon) = J[y_\varepsilon] = \int_{a}^{b} F(x, y + \varepsilon \eta, y' + \varepsilon \eta') dx$$  
此时，泛函 $ J $ 可视为参数 $ \varepsilon $ 的函数，即 $ J = J(\varepsilon) $。

步骤2：泛函取极值的条件转化为函数取极值的条件  
由于 $ y(x) $ 是泛函的极值曲线，因此当 $ \varepsilon = 0 $ 时，函数 $ J(\varepsilon) $ 取极值，根据微积分的极值条件，其导数在 $ \varepsilon = 0 $ 处等于零：  
$$ J'(0) = 0$$

步骤3：计算 $ J'(\varepsilon) $ 并代入 $ \varepsilon = 0 $  
对 $ J(\varepsilon) $ 关于 $ \varepsilon $ 求导（导数与积分可交换顺序）：  
$$ J'(\varepsilon) = \int_{a}^{b} \left( \frac{\partial F}{\partial (y + \varepsilon \eta)} \cdot \eta + \frac{\partial F}{\partial (y' + \varepsilon \eta')} \cdot \eta' \right) dx$$  
代入 $ \varepsilon = 0 $，得：  
$$ J'(0) = \int_{a}^{b} \left( \frac{\partial F}{\partial y} \cdot \eta + \frac{\partial F}{\partial y'} \cdot \eta' \right) dx = 0$$  
根据泛函变分的定义，上式左侧即为泛函的一阶变分 $ \delta J $，因此泛函极值的必要条件为 $ \delta J = 0 $。

#### 3. 核心方程：欧拉-拉格朗日方程的推导
上述积分中含有 $ \eta'(x) $（扰动函数的导数），需通过分部积分消去，才能得到仅含 $ \eta(x) $ 的方程（因 $ \eta(x) $ 是任意扰动函数，其系数必须为零）。

步骤1：对积分中的第二项进行分部积分  
设 $ u = \frac{\partial F}{\partial y'} $，$ dv = \eta'(x) dx $，则 $ du = \frac{d}{dx}\left( \frac{\partial F}{\partial y'} \right) dx $，$ v = \eta(x) $。根据分部积分公式 $ \int_{a}^{b} u dv = uv|_{a}^{b} - \int_{a}^{b} v du $，得：  
$$ \int_{a}^{b} \frac{\partial F}{\partial y'} \cdot \eta' dx = \left. \frac{\partial F}{\partial y'} \cdot \eta(x) \right|_{a}^{b} - \int_{a}^{b} \eta(x) \cdot \frac{d}{dx}\left( \frac{\partial F}{\partial y'} \right) dx$$  

步骤2：利用边界条件简化  
由于扰动函数 $ \eta(x) $ 满足边界条件 $ \eta(a) = \eta(b) = 0 $，因此上式中的边界项为零： 
$$ \left. \frac{\partial F}{\partial y'} \cdot \eta(x) \right|_{a}^{b} = \frac{\partial F}{\partial y'}(a) \cdot 0 - \frac{\partial F}{\partial y'}(b) \cdot 0 = 0$$  

步骤3：整理得到欧拉-拉格朗日方程 
将分部积分结果代入 $ J'(0) = 0 $，得： 
$$ \int_{a}^{b} \eta(x) \left( \frac{\partial F}{\partial y} - \frac{d}{dx}\left( \frac{\partial F}{\partial y'} \right) \right) dx = 0$$ 
由于 $ \eta(x) $ 是任意的扰动函数（只要满足边界条件），要使上述积分对所有 $ \eta(x) $ 都成立，必须保证积分内的被积函数系数为零（这一结论称为变分法基本引理）：  
$$ \frac{\partial F}{\partial y} - \frac{d}{dx} \left( \frac{\partial F}{\partial y'} \right) = 0$$ 
这就是**欧拉-拉格朗日方程**，是变分法的核心。对于多变量泛函（如 $ J[u(x,y)] = \int_{\Omega} F(x,y,u,\nabla u) dxdy $），可类似推导出对应的欧拉-拉格朗日方程（偏微分方程）。


### 三、变分自编码器（VAE）
深度学习的核心是优化模型参数以最小化损失函数，而当模型涉及概率分布隐变量复杂约束时，常规优化方法往往失效。

VAE是2013年由Kingma和Welling提出的生成模型，核心目标是学习数据的概率分布，从而生成新数据。

- 问题背景：生成模型的后验分布难以计算 
  生成模型的核心是学习数据 $ x $ 与隐变量 $ z $ 的联合分布 $ p(x,z) $，并通过后验分布 $ p(z|x) $（给定数据 $ x $，隐变量 $ z $ 的分布）生成新数据。但对于像图片这样的复杂数据，$ p(z|x) = \frac{p(x|z)p(z)}{p(x)} $ 中的证据项 $ p(x) = \int p(x|z)p(z) dz $是高维积分，无法直接计算，导致后验分布难以求解。

- 变分法的解决方案：用变分分布 $ q(z|x) $近似真实后验 $ p(z|x) $ 
  VAE的核心思想是：引入一个易于计算的变分分布 $ q(z|x) $（如高斯分布），通过变分法最小化$ q(z|x) $ 与 $ p(z|x) $ 的KL散度（KL散度衡量两个分布的差异），从而用 $ q(z|x) $ 近似 $ p(z|x) $。

  具体推导如下：
  1. 目标：最小化 $ \text{KL}(q(z|x) || p(z|x)) $，根据KL散度定义： 
     $$ \text{KL}(q||p) = \int q(z|x) \log \frac{q(z|x)}{p(z|x)} dz \geq 0$$ 
     当且仅当 $ q(z|x) = p(z|x) $ 时，KL散度为零。
  2. 代入后验分布 $ p(z|x) = \frac{p(x|z)p(z)}{p(x)} $，整理得： 
     $$ \log p(x) = \text{ELBO}(q) + \text{KL}(q||p)$$ 
     其中，$ \text{ELBO}(q) = \int q(z|x) \log \frac{p(x|z)p(z)}{q(z|x)} dz $ 称为证据下界（Evidence Lower Bound）。
  3. 由于 $ \log p(x) $ 与 $ q $ 无关（$ p(x) $ 是数据的真实分布），最小化 $ \text{KL}(q||p) $ 等价于**最大化 $ \text{ELBO}(q) $**（这是变分法的核心转化：将最小化KL散度转化为最大化泛函ELBO）。
  4. 拆分ELBO为重建项和正则项： 
     $$ \text{ELBO}(q) = \underbrace{\int q(z|x) \log p(x|z) dz}_{\text{重建项：希望生成的 } x \text{ 与真实 } x \text{ 接近}} - \underbrace{\text{KL}(q(z|x) || p(z))}_{\text{正则项：希望 } q(z|x) \text{ 接近先验 } p(z)}$$

  VAE的网络结构正是围绕最大化ELBO设计：
  - 编码器（Encoder）：输入 $ x $，输出变分分布 $ q(z|x) $ 的参数（如高斯分布的均值 $ \mu(x) $ 和方差 $ \sigma^2(x) $）；
  - 解码器（Decoder）：输入隐变量 $ z $（从 $ q(z|x) $ 中采样），输出条件分布 $ p(x|z) $ 的参数（如图片像素的均值）；
  - 损失函数：ELBO的负数（因深度学习中习惯最小化损失），即 $ \text{Loss} = -\text{ELBO}(q) $，包含重建损失MSE和KL散度损失。

- 应用场景：图像生成、数据增强、异常检测  
  VAE可生成与训练数据风格一致的新图像（如生成手写数字、人脸），也可通过隐变量的插值实现图像编辑（如从微笑人脸插值到皱眉人脸）。在异常检测中，可通过计算ELBO值判断数据是否异常——异常数据的ELBO值更低（因难以被模型重建）。



其设计灵感可以说来自变分法和深度学习，但是**VAE只是借用了"变分"这个名字，实际做法与经典变分法相去甚远**，它更像是用变分推断的思想解决自编码问题，而不是用变分法优化函数。

当然我们可以以下表表示变分法跟VAE中变分的术语对应的关系

| VAE组件      | 数学对应               | 具体形式/含义                                                |
| ------------ | ---------------------- | ------------------------------------------------------------ |
| **真实后验** | 变分法中的真实极值函数 | $ p(z\|x) $ - 我们想得到但很难计算的                         |
| **变分分布** | 变分法中的试探函数     | $ q_\phi(z\|x) = \mathcal{N}(z; \mu_\phi(x), \sigma_\phi(x)) $ |
| **ELBO目标** | 变分法中的泛函         | $ \mathcal{L}(\phi, \theta) = \mathbb{E}_{q_\phi}[\log p_\theta(x\|z)] - D_{KL}(q_\phi(z\|x) \| p(z)) $ |
| **编码器**   | 产生试探函数的机制     | 神经网络 $ \text{Encoder}(x) \rightarrow (\mu, \sigma) $     |
| **解码器**   | 观测模型               | 神经网络 $ \text{Decoder}(z) \rightarrow \text{数据分布参数} $ |
| **重参数化** | 计算技巧               | $ z = \mu + \sigma \odot \epsilon, \epsilon \sim \mathcal{N}(0,I) $ |



### 四、References

[1]Calculus of variations https://en.wikipedia.org/wiki/Calculus_of_variations

[2]Variational autoencoder https://en.wikipedia.org/wiki/Variational_autoencoder

